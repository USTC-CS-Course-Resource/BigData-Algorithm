## 次线性算法

[toc]

考虑 Metric Graph. $G = (V, E)$, 完全带权图.

$\forall v_1, v_2, v_3 \in V$, 
$$\left\{\begin{array}{l}
w(v_1, v_3) \le w(v, v_2) + w(v_2, v_3) \\
\forall w(e) \ge 0 \\
w(v_i, v_i) = 0 \\
w(v_i, v_j) = w(v_j, v_i) & 即无向
\end{array}\right.$$

例如: 生物信息, 蛋白质结构, 编辑距离, 

输入数据大小: $\Theta(n^2)$, 要求次线性时间 $o(n^2)$

### Problem I. 1-median

#### Target

从 $V$ 中找到一个顶点 $u$, s.t. $\sum\limits_{v\in V} w(u,v)$ 最小.

在欧式空间就是给定 $P \subseteq \mathbb{R}^d$ 和 $q \in \mathbb{R}^d$, s.t. $\sum\limits_{p \in P} \|q - p\|^2$ 最小

#### 问题抽象
- 记 $f(u)=\sum\limits_{v \in V} w(u, v)$, 尝试找 $(1+\delta)$ 近似的解($\delta\in(0,1)$), 即返回 $u_0$, s.t.
$$f(u_0) \le (1+\delta) f(u_{opt})$$
- 目标时间: $\Theta(n\cdot poly(\frac{\log n}{\delta}))=o(n^2)$
- 以预言 (**Oracle**) 的方式给出解: 假设$\exists Oracle\ T$, $\forall u_1, u_2 \in V$, $T$ 都在 $n$ 次比较内能判断 $f(u_1) 和 f(u_2)$ 的大小关系, 且 $T$ 正确的概率为 $\frac{2}{3}$
  $E(\sharp正确)=\frac{2}{3}s$, $E(\sharp错误)=\frac{1}{3}s$, 
  $$P[\sharp正确 > \sharp 错误] \ge 1 - \frac{1}{5n}$$
  要求 $s=\Theta(\log n)$, 故调用 $T$ 的次数是 $\Theta(n\log n)=o(n^2)$
- **关于 Oracle $T$ 本身**: 要求 $T$ 能够以 $\frac{2}{3}$ 的概率返回:
  $$\left\{\begin{array}{l}
  f(u_1) > (1+\delta) f(u_2) & 返回 "f(u_2) < f(u_1) \\
  f(u_2) > (1+\delta) f(u_1) & 返回 "f(u_1) < f(u_2) \\
  \frac{1}{1+\delta} \le \frac{f(u_1)}{f(u_2)} \le 1+\delta & 返回以上任意一种答案
  \end{array}\right.$$

#### 若已有这样的 $T$, 则算法为
- 逐个尝试比较, 需要 n 次.
- 如下:
  $$\left\{\begin{array}{l}
  f(u_2) \le (1+\delta) f(u_1) \\
  f(u_3) \le (1+\delta) f(u_2) \\
  \cdots \\
  f(u_n) \le (1+\delta) f(u_{n-1})
  \end{array}\right.$$
  因此 $f(u_n) \le (1+\delta)^{n-1} f(u_{opt})$, 其中 $(1+\delta)^{n-1}$ 即近似比.
  上述近似比是线性比较的, 如果用树结构比较, 则是层与层之间才要多 $(1+\delta)$ 倍, 因此近似比变成了 $(1+\delta)^{\log n}$

#### 建立 $T$

> 下面这个部分没看懂在干嘛
> ![](./image/9.stream/1.png)

### Problem II. 估计权和均值

估计 $y = \frac{1}{C_n^2} \sum\limits_{e\in E} w(e)$

#### 算法

Sample $s$ edges from $Z$,
let $\widetilde{y}=\frac{1}{s}\sum\limits_{e\in Q}w(e), |Q|=s$

**A simple case**: $\forall e \in Z, 1 \le w(e) \le 2$ (若不是, 放缩一下即可), 此时则可用 Hoeffding Bound.

But now, $\forall e, 1 \le w(e) \le \Delta$, where $\Delta$ might be very big.

考虑对区间 $[1, \Delta]$ 划分为 $B_1=[1, 1+\epsilon], B_2=[1+\epsilon, (1+\epsilon)^2], \cdots, B_N=[..., \Delta]$, 区间数大致为 $N=\log_{1+\epsilon}\Delta=\Theta(\frac{1}{\epsilon}\log\Delta)$.

**理想情况**: $\forall B_j, |Q\cap B_j|=s_j$, $\frac{s_j}{s} \in (1 \pm \epsilon)\frac{|B_j|}{C_n^2}$.
**断言**: 若满足*理想情况*, 则 $\widetilde{y}$ 与真实值差距也很小.

$$\begin{aligned}
y &= \frac{1}{C_n^2} \sum\limits_{e\in E}w(e) \\
&= \frac{|B_1|}{C_n^2} \frac{1}{|B_1|} \sum\limits_{e \in B_1} w(e) + \cdots + \frac{|B_N|}{C_n^2} \frac{1}{|B_N|}\sum\limits_{e\in B_N} w(e)
\end{aligned}$$

$$\begin{aligned}
\widetilde{y} &= \frac{1}{s} \sum\limits_{e\in Q}w(e) \\
&= \frac{s_1}{s} \frac{1}{s_1} \sum\limits_{e \in B_1 \cap Q} w(e) + \cdots + \frac{s_N}{s} \frac{1}{s_N}\sum\limits_{e\in B_N \cap Q} w(e)
\end{aligned}$$

对于 $\frac{s_i}{s}\frac{1}{s_i}\sum\limits_{e\in B_i\cap Q}w(e)$ 和 $\frac{|B_i|}{s}\frac{1}{|B_i|}\sum\limits_{e\in B_i}w(e)$, 前面比值之比在 $[1-\epsilon, 1+\epsilon]$, 后面均值之比在 $[\frac{1}{1+\epsilon}, 1+\epsilon]$, 因此每项乃至整体求和的误差在 $[\frac{1-\epsilon}{1+\epsilon}, (1+\epsilon)^2]$

如果 $|B_j| \ll C_n^2$, $B_j$ 可以忽略.(主要想法是利用三角不等式, 某些桶会非常大, 以至于 $B_j$ 可以忽略).
> 强烈建议阅读 Sublinear-Time Approximation for Clustering via Random Sampling




