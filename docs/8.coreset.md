## Coreset

前面很多方法考虑的是压缩维度, 如 PCA, JL 等. 而考虑压缩数据量的有主要是 sampling(uniform or non-uniform).

**Coreset** 考虑的是压缩数据量. 

[toc]

### Coreset

对 $\epsilon \in (0,1)$, $S \subseteq R^d$ 是 $P$ 的一个 $\epsilon$-coreset, 如果 $|S| \ll n$, $\forall C\in F$ ($F$ 是对应解空间), 有
$$(1-\epsilon)f(P,C) \le f(S, C) \le (1+\epsilon) f(P,C)$$

例如我们有一个对 $f$ 的 $\lambda$ 倍近似比的算法. 如果对 $S$ 运行这个算法, 得到 $C^*$, 那么对于 $P$, $C^*$ 的近似比如下求出:  
令 $C_{opt}$ 是对 $P$ 的最优解, 则由于:
1. $f(S,C^*) \le \lambda f(S, C_{opt})$
2. $f(S, C_{opt}) \le (1+\epsilon) f(P, C_{opt})$
3. $f(S, C^*) \ge (1-\epsilon) f(P, C^*)$

可得 $f(P, C^*) \le \frac{1+\epsilon}{1-\epsilon}\lambda f(P, C_{opt})$

### Coreset for K-means

#### K-means Revisit

K-means 的目标是
$$\mathtt{minimize}:\ \frac{1}{n}\sum\limits_{i=1}^n\min \|p_i-c_j\|^2$$

并设 $\{C_1,C_2,\cdots, C_k\} \subseteq R$ 是其解.

若做 Uniform Sample
...
**TODO**

#### 对于 K-means 的 Coreset 构造

1. 用一个 cheap 的算法得到一个粗糙的结果(如 K-means++, $\Theta(\log k))$, 其具有 $\alpha$-approx 的解. 设这个解为 $A=\{a_1,\cdots,a_k\}$
2. 对空间划分.
$\forall a_j$, 划分 $\phi = \log_2(\alpha n)$ 层, $R=\frac{1}{\alpha}f(P,A)$
